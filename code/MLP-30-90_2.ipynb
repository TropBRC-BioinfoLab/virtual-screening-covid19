{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score,f1_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class uji(): \n",
    "    def __init__(self,data): \n",
    "        df0 = pd.read_csv('../data2_smpl30_2/uji%snorm.csv'%data, delimiter= \",\", header=None)\n",
    "        df0=df0.fillna(0)\n",
    "        self.com=df0[0]\n",
    "        self.prot=df0[1282]\n",
    "        self.x =df0.drop([0,1282], axis=1)\n",
    "        df0[1300]=0\n",
    "        \n",
    "        self.y=df0[1300]\n",
    "        self.dt=data\n",
    "\n",
    "def dtuji(data): \n",
    "    return uji(data) \n",
    "\n",
    "\n",
    "dtf =dtuji('mbafika') #dtf.com, dtf.prot, dtf.x, dtf.y, dtf.dt\n",
    "dtl =dtuji('mbalinda') #dtl.com, dtl.prot, dtl.x, dtl.y dtl.dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtg =dtuji('gabung') #dtl.com, dtl.prot, dtl.x, dtl.y dtl.dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/biofarmaka/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3325: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class latih(): \n",
    "    def __init__(self,data): \n",
    "        df = pd.read_csv(\"../data2_smpl30_2/%s.csv\"%data, delimiter=',')\n",
    "        df.head()\n",
    "        self.X = df.drop(['0','1282','0.1'], axis=1)\n",
    "        self.Y = df['0.1']\n",
    "        self.dt=data\n",
    "\n",
    "def dtlatih(data): \n",
    "    return latih(data) \n",
    "df1= dtlatih('latih_sampled30_1') #df1.X,df1.Y,df1.dt\n",
    "df2= dtlatih('latih_sampled30_2') #df2.X,df2.Y,df2.dt\n",
    "df3= dtlatih('latih_sampled30_3') #df3.X,df3.Y,df3.dt\n",
    "df4= dtlatih('latih_sampled30_4') #df4.X,df4.Y,df4.dt\n",
    "df5= dtlatih('latih_sampled30_5') #df5.X,df5.Y,df5.dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "du5=dtlatih('uji_sampled30_5') #df5.X,df5.Y,df5.dt\n",
    "du4=dtlatih('uji_sampled30_4') #df5.X,df5.Y,df5.dt\n",
    "du3=dtlatih('uji_sampled30_3') #df5.X,df5.Y,df5.dt\n",
    "du2=dtlatih('uji_sampled30_2') #df5.X,df5.Y,df5.dt\n",
    "du1=dtlatih('uji_sampled30_1') #df5.X,df5.Y,df5.dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'AUC': 'roc_auc', 'Accuracy': 'accuracy','F-measure':'f1','Precision':'precision', 'Recall':'recall'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(640, input_dim=1281, init='normal', activation='relu'))\n",
    "    model.add(Dense(320, init='normal', activation='relu'))\n",
    "    model.add(Dense(1, init='normal', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(df):\n",
    "    mlp = MLPClassifier(max_iter=1000,hidden_layer_sizes=(640,320,),activation= 'relu',\n",
    "                        solver= 'adam')\n",
    "#    model = Sequential()\n",
    "#    model.add(Dense(640, input_dim=1281, init='uniform', activation='relu'))\n",
    "#    model.add(Dense(320, init='uniform', activation='relu'))\n",
    "#    model.add(Dense(1, init='uniform', activation='sigmoid'))\n",
    "#    estimators = []\n",
    "#    estimators.append(('standardize', StandardScaler()))\n",
    "#    estimators.append(('mlp', KerasClassifier(build_fn=create_model, nb_epoch=100, batch_size=128, verbose=0,class_weight=\"balanced\")))\n",
    "#    pipeline = Pipeline(estimators)\n",
    "#    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#    results = cross_val_score(pipeline, df.X, df.Y, cv=kfold)\n",
    "#    print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    parameter_space = {\n",
    "        #'hidden_layer_sizes': [(640,320,)],\n",
    "        #'activation': ['relu'],\n",
    "        #'solver': ['adam'],\n",
    "        'alpha': [0.5,0.01],\n",
    "        'learning_rate': ['constant','adaptive'],\n",
    "        'batch_size':[32,64,128,256,512]\n",
    "    }\n",
    "    mlp = GridSearchCV(mlp, parameter_space, n_jobs=15, cv=5,scoring=scoring, refit='AUC',return_train_score=True)\n",
    "    mlp.fit(df.X, df.Y)\n",
    "    print('done_training')\n",
    "    filename = '../data2_smpl30_2/model/mlp_{0}'.format(df.dt)\n",
    "    pickle.dump(mlp, open(filename, 'wb'))\n",
    "    print('done_savemodel')\n",
    "    return mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf5_100n_1000m.cv_results_#['mean_test_score']\n",
    "#stds = clf.cv_results_['std_test_score']\n",
    "def print_cv_results_mlp(model,o):\n",
    "    rf = pickle.load(open('../data2_smpl30_2/model/{0}_{1}'.format(model.__name__,o.dt), 'rb'))\n",
    "    print('{0}_{1}'.format(model.__name__,o.dt))\n",
    "    print('Best parameters found:', rf.best_params_)\n",
    "    print('AUC :',rf.cv_results_['mean_test_AUC'])\n",
    "    print('Accuracy :',rf.cv_results_['mean_test_Accuracy'])\n",
    "    print('F-measure :',rf.cv_results_['mean_test_F-measure'])\n",
    "    print('Precision :',rf.cv_results_['mean_test_Precision'])\n",
    "    print('Recall :',rf.cv_results_['mean_test_Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_rf(model,df,d):\n",
    "    rf = pickle.load(open('../data2_smpl30_2/model/{0}_latih_sampled30_{1}'.format(model.__name__,d), 'rb'))\n",
    "    pred_x = rf.predict(df.X)\n",
    "    \n",
    "    print('model file : {0}_{1}'.format(model.__name__,d))\n",
    "    #print('Parameters used:', rf.get_params() )\n",
    "    print('Best parameters found:', rf.best_params_)\n",
    "    print('CV RESULT :')\n",
    "    print('AUC :',rf.cv_results_['mean_test_AUC'][(rf.cv_results_['rank_test_AUC']-1)[0]])\n",
    "    print('Accuracy :',rf.cv_results_['mean_test_Accuracy'][(rf.cv_results_['rank_test_Accuracy']-1)[0]])\n",
    "    print('F-measure :',rf.cv_results_['mean_test_F-measure'][(rf.cv_results_['rank_test_F-measure']-1)[0]])\n",
    "    print('Precision :',rf.cv_results_['mean_test_Precision'][(rf.cv_results_['rank_test_Precision']-1)[0]])\n",
    "    print('Recall :',rf.cv_results_['mean_test_Recall'][(rf.cv_results_['rank_test_Recall']-1)[0]])\n",
    "    #print('Accuracy:',accuracy_score(df.Y, pred_x))\n",
    "    #print('f1:',f1_score(df.Y, pred_x))\n",
    "    #print('precision:',precision_score(df.Y, pred_x))\n",
    "    #print('recall:',recall_score(df.Y, pred_x))\n",
    "    #print('roc_auc:',roc_auc_score(df.Y, pred_x))\n",
    "    #print('Confusion matrix:')\n",
    "    #print(confusion_matrix(df.Y, pred_x))\n",
    "    #print('Results on the train set:')\n",
    "    #print(classification_report(df.Y, pred_x))\n",
    "    return rf\n",
    "    #pred_n = rf.predict(cX)\n",
    "    #print('Results on the all neg data:')\n",
    "    #print(classification_report(cY, pred_n))\n",
    "    \n",
    "def prediksi(md,model,p,data,d):\n",
    "    pred_x = pd.DataFrame(md.predict_proba(data.x))\n",
    "    prob_x = pd.DataFrame(np.where(pred_x >= p, 1,0))\n",
    "    print(\"threshold {0} \".format(p))\n",
    "    print(\"model_hasilsmote_{0} \".format(d))\n",
    "    print(\"hasil prediksi \",data.dt,\" : (0,1)\")\n",
    "    print(confusion_matrix(data.y, prob_x[1]))\n",
    "    pred = pd.DataFrame(prob_x)\n",
    "    pred[2] = data.com\n",
    "    pred[3] = data.prot\n",
    "    #print(pred.head())\n",
    "    #print(prob_x)\n",
    "    pred[4] = pred_x[1]\n",
    "    #print(pred.head())\n",
    "    #print(pd.DataFrame(prob_x)[1].head())\n",
    "    pred.to_excel('../data2_smpl30_2/hasil_pred/{0}_{1}p_{2}_latih_sampled30_{3}.xlsx'.format(model.__name__,p,data.dt,d))\n",
    "    \n",
    "def prediksi2(md,model,p,data,d):\n",
    "    pred_x = pd.DataFrame(md.predict_proba(data.X))\n",
    "    prob_x = pd.DataFrame(np.where(pred_x >= p, 1,0))\n",
    "    print(\"threshold {0} \".format(p))\n",
    "    print(\"model_hasilsmote_{0} \".format(d))\n",
    "    print(\"hasil prediksi \",data.dt,\" : (0,1)\")\n",
    "    print(data.Y.value_counts())\n",
    "    print(confusion_matrix(data.Y, prob_x[1]))\n",
    "    pred = pd.DataFrame(prob_x)\n",
    "    #pred[2] = data.com\n",
    "    #pred[3] = data.prot\n",
    "    print('Accuracy:',accuracy_score(data.Y, prob_x[1]))\n",
    "    print('f1:',f1_score(data.Y, prob_x[1]))\n",
    "    print('precision:',precision_score(data.Y, prob_x[1]))\n",
    "    print('recall:',recall_score(data.Y, prob_x[1]))\n",
    "    print('roc_auc:',roc_auc_score(data.Y, prob_x[1]))\n",
    "    print('Confusion matrix:')\n",
    "    print(confusion_matrix(data.Y, prob_x[1]))\n",
    "    print('Results on the train set:')\n",
    "    print(classification_report(data.Y, prob_x[1]))\n",
    "    #print(pred.head())\n",
    "    #print(prob_x)\n",
    "    #pred[4] = pred_x[1]\n",
    "    #print(pred.head())\n",
    "    #print(pd.DataFrame(prob_x)[1].head())\n",
    "    #pred.to_excel('../data2_smpl30_2/hasil_pred/{0}_{1}p_{2}_latih_sampled30_{3}.xlsx'.format(model.__name__,p,data.dt,d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitn3pred(model,p,datalatih,datauji1,datauji2,datauji3,d):\n",
    "    mlp(datalatih)\n",
    "    md=report_rf(model,datalatih,d)\n",
    "    prediksi(md,model,p,datauji1,d)\n",
    "    prediksi(md,model,p,datauji2,d)\n",
    "    prediksi2(md,model,p,datauji3,d)\n",
    "def fitn2pred(model,p,datalatih,datauji1,datauji2,d):\n",
    "    mlp(datalatih)\n",
    "    md=report_rf(model,datalatih,d)\n",
    "    prediksi(md,model,p,datauji1,d)\n",
    "    prediksi(md,model,p,datauji2,d)\n",
    "def fitnpred(model,p,datalatih,datauji1,d):\n",
    "    mlp(datalatih)\n",
    "    md=report_rf(model,datalatih,d)\n",
    "    prediksi(md,model,p,datauji1,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done_training\n",
      "done_savemodel\n",
      "model file : mlp_1\n",
      "Best parameters found: {'alpha': 0.5, 'batch_size': 256, 'learning_rate': 'adaptive'}\n",
      "CV RESULT :\n",
      "AUC : 0.9945650736500837\n",
      "Accuracy : 0.9791597486805308\n",
      "F-measure : 0.9782794593899654\n",
      "Precision : 0.9707172216688003\n",
      "Recall : 0.9960651289009498\n",
      "threshold 0.5 \n",
      "model_hasilsmote_1 \n",
      "hasil prediksi  mbafika  : (0,1)\n",
      "[[138 102]\n",
      " [  0   0]]\n",
      "threshold 0.5 \n",
      "model_hasilsmote_1 \n",
      "hasil prediksi  mbalinda  : (0,1)\n",
      "[[1753 1295]\n",
      " [   0    0]]\n",
      "threshold 0.5 \n",
      "model_hasilsmote_1 \n",
      "hasil prediksi  uji_sampled30_1  : (0,1)\n",
      "0    3537\n",
      "1    3086\n",
      "Name: 0.1, dtype: int64\n",
      "[[3423  114]\n",
      " [   0 3086]]\n",
      "Accuracy: 0.9827872565302733\n",
      "f1: 0.9818644607063315\n",
      "precision: 0.964375\n",
      "recall: 1.0\n",
      "roc_auc: 0.9838846480067854\n",
      "Confusion matrix:\n",
      "[[3423  114]\n",
      " [   0 3086]]\n",
      "Results on the train set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98      3537\n",
      "           1       0.96      1.00      0.98      3086\n",
      "\n",
      "    accuracy                           0.98      6623\n",
      "   macro avg       0.98      0.98      0.98      6623\n",
      "weighted avg       0.98      0.98      0.98      6623\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fitn3pred(mlp,0.5,df1,dtf,dtl,du1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(df):\n",
    "    mlp = MLPClassifier(max_iter=1000, batch_size=128,hidden_layer_sizes=(640,320,),activation= 'relu',\n",
    "                        solver= 'adam')\n",
    "#    model = Sequential()\n",
    "#    model.add(Dense(640, input_dim=1281, init='uniform', activation='relu'))\n",
    "#    model.add(Dense(320, init='uniform', activation='relu'))\n",
    "#    model.add(Dense(1, init='uniform', activation='sigmoid'))\n",
    "#    estimators = []\n",
    "#    estimators.append(('standardize', StandardScaler()))\n",
    "#    estimators.append(('mlp', KerasClassifier(build_fn=create_model, nb_epoch=100, batch_size=128, verbose=0,class_weight=\"balanced\")))\n",
    "#    pipeline = Pipeline(estimators)\n",
    "#    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#    results = cross_val_score(pipeline, df.X, df.Y, cv=kfold)\n",
    "#    print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    parameter_space = {\n",
    "        #'hidden_layer_sizes': [(640,320,)],\n",
    "        #'activation': ['relu'],\n",
    "        #'solver': ['adam'],\n",
    "        'alpha': [0.5],\n",
    "        'learning_rate': ['adaptive'],\n",
    "        'batch_size':[256]\n",
    "    }\n",
    "    mlp = GridSearchCV(mlp, parameter_space, n_jobs=3, cv=5,scoring=scoring, refit='AUC',return_train_score=True)\n",
    "    mlp.fit(df.X, df.Y)\n",
    "    print('done_training')\n",
    "    filename = '../data2_smpl30_2/model/mlp_{0}'.format(df.dt)\n",
    "    pickle.dump(mlp, open(filename, 'wb'))\n",
    "    print('done_savemodel')\n",
    "    return mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done_training\n",
      "done_savemodel\n",
      "model file : mlp_2\n",
      "Best parameters found: {'alpha': 0.5, 'batch_size': 256, 'learning_rate': 'adaptive'}\n",
      "CV RESULT :\n",
      "AUC : 0.995868440564764\n",
      "Accuracy : 0.9824603845175315\n",
      "F-measure : 0.9817814959655253\n",
      "Precision : 0.9645734772207024\n",
      "Recall : 0.9997254632807138\n",
      "threshold 0.5 \n",
      "model_hasilsmote_2 \n",
      "hasil prediksi  mbafika  : (0,1)\n",
      "[[163  77]\n",
      " [  0   0]]\n",
      "threshold 0.5 \n",
      "model_hasilsmote_2 \n",
      "hasil prediksi  mbalinda  : (0,1)\n",
      "[[1965 1083]\n",
      " [   0    0]]\n",
      "threshold 0.5 \n",
      "model_hasilsmote_2 \n",
      "hasil prediksi  uji_sampled30_2  : (0,1)\n",
      "0    3450\n",
      "1    3173\n",
      "Name: 0.1, dtype: int64\n",
      "[[3325  125]\n",
      " [   0 3173]]\n",
      "Accuracy: 0.9811263777744225\n",
      "f1: 0.9806830474424354\n",
      "precision: 0.962098241358399\n",
      "recall: 1.0\n",
      "roc_auc: 0.9818840579710144\n",
      "Confusion matrix:\n",
      "[[3325  125]\n",
      " [   0 3173]]\n",
      "Results on the train set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98      3450\n",
      "           1       0.96      1.00      0.98      3173\n",
      "\n",
      "    accuracy                           0.98      6623\n",
      "   macro avg       0.98      0.98      0.98      6623\n",
      "weighted avg       0.98      0.98      0.98      6623\n",
      "\n",
      "done_training\n",
      "done_savemodel\n",
      "model file : mlp_3\n",
      "Best parameters found: {'alpha': 0.5, 'batch_size': 256, 'learning_rate': 'adaptive'}\n",
      "CV RESULT :\n",
      "AUC : 0.9955132587010882\n",
      "Accuracy : 0.9782538929704048\n",
      "F-measure : 0.9776561030413442\n",
      "Precision : 0.9567041837020916\n",
      "Recall : 0.9995915588835942\n",
      "threshold 0.5 \n",
      "model_hasilsmote_3 \n",
      "hasil prediksi  mbafika  : (0,1)\n",
      "[[195  45]\n",
      " [  0   0]]\n",
      "threshold 0.5 \n",
      "model_hasilsmote_3 \n",
      "hasil prediksi  mbalinda  : (0,1)\n",
      "[[2194  854]\n",
      " [   0    0]]\n",
      "threshold 0.5 \n",
      "model_hasilsmote_3 \n",
      "hasil prediksi  uji_sampled30_3  : (0,1)\n",
      "0    3513\n",
      "1    3110\n",
      "Name: 0.1, dtype: int64\n",
      "[[3397  116]\n",
      " [   8 3102]]\n",
      "Accuracy: 0.9812773667522271\n",
      "f1: 0.9804045512010113\n",
      "precision: 0.963952765692977\n",
      "recall: 0.997427652733119\n",
      "roc_auc: 0.9822037210434739\n",
      "Confusion matrix:\n",
      "[[3397  116]\n",
      " [   8 3102]]\n",
      "Results on the train set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98      3513\n",
      "           1       0.96      1.00      0.98      3110\n",
      "\n",
      "    accuracy                           0.98      6623\n",
      "   macro avg       0.98      0.98      0.98      6623\n",
      "weighted avg       0.98      0.98      0.98      6623\n",
      "\n",
      "done_training\n",
      "done_savemodel\n",
      "model file : mlp_4\n",
      "Best parameters found: {'alpha': 0.5, 'batch_size': 256, 'learning_rate': 'adaptive'}\n",
      "CV RESULT :\n",
      "AUC : 0.9952611923918135\n",
      "Accuracy : 0.982201505780955\n",
      "F-measure : 0.9815797779958432\n",
      "Precision : 0.9651638112830696\n",
      "Recall : 0.9986348122866893\n",
      "threshold 0.5 \n",
      "model_hasilsmote_4 \n",
      "hasil prediksi  mbafika  : (0,1)\n",
      "[[157  83]\n",
      " [  0   0]]\n",
      "threshold 0.5 \n",
      "model_hasilsmote_4 \n",
      "hasil prediksi  mbalinda  : (0,1)\n",
      "[[1751 1297]\n",
      " [   0    0]]\n",
      "threshold 0.5 \n",
      "model_hasilsmote_4 \n",
      "hasil prediksi  uji_sampled30_4  : (0,1)\n",
      "0    3492\n",
      "1    3131\n",
      "Name: 0.1, dtype: int64\n",
      "[[3378  114]\n",
      " [   0 3131]]\n",
      "Accuracy: 0.9827872565302733\n",
      "f1: 0.9821204516938519\n",
      "precision: 0.964869029275809\n",
      "recall: 1.0\n",
      "roc_auc: 0.9836769759450172\n",
      "Confusion matrix:\n",
      "[[3378  114]\n",
      " [   0 3131]]\n",
      "Results on the train set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98      3492\n",
      "           1       0.96      1.00      0.98      3131\n",
      "\n",
      "    accuracy                           0.98      6623\n",
      "   macro avg       0.98      0.98      0.98      6623\n",
      "weighted avg       0.98      0.98      0.98      6623\n",
      "\n",
      "done_training\n",
      "done_savemodel\n",
      "model file : mlp_5\n",
      "Best parameters found: {'alpha': 0.5, 'batch_size': 256, 'learning_rate': 'adaptive'}\n",
      "CV RESULT :\n",
      "AUC : 0.9950400462716484\n",
      "Accuracy : 0.9828490481290812\n",
      "F-measure : 0.9821446405154962\n",
      "Precision : 0.9678328302033592\n",
      "Recall : 0.9969883641341546\n",
      "threshold 0.5 \n",
      "model_hasilsmote_5 \n",
      "hasil prediksi  mbafika  : (0,1)\n",
      "[[178  62]\n",
      " [  0   0]]\n",
      "threshold 0.5 \n",
      "model_hasilsmote_5 \n",
      "hasil prediksi  mbalinda  : (0,1)\n",
      "[[2078  970]\n",
      " [   0    0]]\n",
      "threshold 0.5 \n",
      "model_hasilsmote_5 \n",
      "hasil prediksi  uji_sampled30_5  : (0,1)\n",
      "0    3473\n",
      "1    3150\n",
      "Name: 0.1, dtype: int64\n",
      "[[3396   77]\n",
      " [   2 3148]]\n",
      "Accuracy: 0.9880718707534349\n",
      "f1: 0.9876078431372548\n",
      "precision: 0.9761240310077519\n",
      "recall: 0.9993650793650793\n",
      "roc_auc: 0.9885970228383129\n",
      "Confusion matrix:\n",
      "[[3396   77]\n",
      " [   2 3148]]\n",
      "Results on the train set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      3473\n",
      "           1       0.98      1.00      0.99      3150\n",
      "\n",
      "    accuracy                           0.99      6623\n",
      "   macro avg       0.99      0.99      0.99      6623\n",
      "weighted avg       0.99      0.99      0.99      6623\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fitn3pred(mlp,0.5,df2,dtf,dtl,du2,2)\n",
    "fitn3pred(mlp,0.5,df3,dtf,dtl,du3,3)\n",
    "fitn3pred(mlp,0.5,df4,dtf,dtl,du4,4)\n",
    "fitn3pred(mlp,0.5,df5,dtf,dtl,du5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
